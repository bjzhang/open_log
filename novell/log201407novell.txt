.LOG
12:54 2014-07-01
GTD
0, -18:00

1, today
1), health check.
2), 13:40-14:12 nap.
3), 14:12-17:53 snapshot doc.

14:35 2014-07-01
snapshot
1, comment
 * load domain snapshot configuration file(format: libxl-json) to
 * libxl_domain_snapshot struct for the domain domid and
 * domain snapshot name(snapshot->name).

 * store libxl_domain_snapshot struct to domain snapshot configuration
 * file(format: libxl-json) belong to specific domain(domain id: domid).
 * file name will be snapshotdata-<snapshot_name>.libxl-json
2, snapshot
libxl__qmp_disk_snapshot_transaction do not support external snapshot.
3, 突然忘了snapshot里面的path什么时候会用到?
path is only used when invoke qemu-img command. currently, only revert.
libxl_disk_to_snapshot is in wrong version. it could merge snapshot struct and disk info.
TODO consider how to deal with it.
4, TODO
感觉libxl_disk_to_snapshot函数问题很多啊, 什么是否判断是否可以做snapshot呢?
感觉还是需要加type的, 如果用户需要指明全局的type, 每个disk可以覆盖全局的flag.
否则就是操作disk snapshot时, 检查是否可以做snapshot. 但是这样感觉比较乱
(16:02 2014-07-02)
已经加了type, 改代码吧。

16:12 2014-07-01
bash
set -x
set +x

09:50 2014-07-02
suse, colleague, L3/Maintenance, Vit Pelcak
All,

I'm glad to announce that Vit Pelcak takes over the role
of Team Lead Maintenance QA Prague in the L3/Maintenance department.

Together with Heiko Rommel and Tony Yuan, who lead the Nuremberg and the China
QA Maintenace teams, he will lead our QA Maintenance effort.

Please join me in congratulating Vit to his new role and in
offering him our full support for his work.


Thanks a lot,
Mike

--
Michael Hager
Director L3/Maintenance

SUSE LINUX Products GmbH
Maxfeldstr. 5, D-90409 Nürnberg
GF:  Jeff Hawn, Jennifer Guild, Felix Imendörffer, HRB 16746 (AG Nürnberg)

09:52 2014-07-02
suse, colleague, team, suse lab, performance
Hello all,

I'd like to introduce a new team in the Labs, one that will be focusing on
tracking, understanding and improving the performance characteristics of SLES.

The team will be led by

Mel Gorman

and

Jan Kára
Mike Galbraith
Jan "Moskyto" Matějka
Tony Jones

will be the initial crew. I expect the team to grow as it takes on new
challenges.

I welcome Mel in his new role as a teamlead, and wish both him and the
team a lot of success!

--
Vojtech Pavlik
Director SUSE Labs

10:10 2014-07-02
GTD
0, 9:40-17:55

1, today
1), 10:11-10:18 summary virtualization. see"10:11 2014-07-02"
TODO: add my voice recording.
2), 10:19-17:49 snapshot doc.
3), 11:15-14:00 send stuff to my parents.

10:11 2014-07-02
summay, virtualization, kernel; qemu; management tools
1, 从虚拟化技术看内核的新feature.
1), memory relative
tmem: 最开始为了xen引入.
ksm: for kvm?
huge tlb, transparent tlb.
2), pvops

2, qemu
multi data pane.

3, management tools
看起来用libvirt控制xen或kvm虚拟机是一样的. 其实libvirt控制xen经常要通过hypercall到xen hypervisor. 控制qemu多数是直接和qemu进程打交道. 如果有必要qemu或通过kvm fd和kernel kvm module说话.

10:35 2014-07-02
software skill, quilt import

18:10 2014-07-02
software skill, language, locale
LANG=zh_CN.utf8 LC_ALL=zh_CN.utf8 man ls

10:21 2014-07-03
GTD
0, 10:13

1, today
1), send snapshot doc v5 candidate to Chunyan and Roger.
2), 10:20-11:35 snapshot code.
3), 11:35-12:19 lunch.
4), 13:30-14:20 go to hospital

12:33 2014-07-03
/usr/bin/qemu-kvm -name clmd_n1_sles12 -S -machine pc-i440fx-1.4,accel=kvm,usb=off -m 768 -smp 4,sockets=4,cores=1,threads=1 -uuid a4eb4367-b880-3b11-d1e8-d5d2b2c1a3aa -no-user-config -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/clmd_n1_sles12.monitor,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc -no-shutdown -device piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2 -drive file=/mnt/vm/clmd_n1_sles12/disk0.raw,if=none,id=drive-virtio-disk0,format=raw -device virtio-blk-pci,scsi=off,bus=pci.0,addr=0x4,drive=drive-virtio-disk0,id=virtio-disk0,bootindex=1 -netdev tap,fd=23,id=hostnet0,vhost=on,vhostfd=25 -device virtio-net-pci,netdev=hostnet0,id=net0,mac=52:54:00:0c:78:00,bus=pci.0,addr=0x3 -vnc 0.0.0.0:0 -vga cirrus -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5

11:17 2014-07-04
GTD
0,

1, today
1), 13:39-18:19 virtualization summary.

13:16 2014-07-04
software skill, system, log, rsyslog; mailing list, suse, research
1, "Marcus Rueckert <mrueckert@suse.de>"_email_"sean <xrfu@novell.com>"_"[Research] Does "syslogd" support encrypted transmission?"_20140630_1540
On 2014-06-30 09:39, sean wrote:
>   Does "syslogd" support encrypted transmission?
> If yes, Could you tell me how to set it?

use rsyslog.

for older distributions you could try TCP syslog via stunnel.

2, http://www.rsyslog.com/
RSYSLOG is the Rocket-fast SYStem for LOG processing.

It offers high-performance, great security features and a modular design. While it started as a regular syslogd, rsyslog has evolved into a kind of swiss army knife of logging, being able to accept inputs from a wide variety of sources, transform them, and output to the results to diverse destinations.

RSYSLOG can deliver over one million messages per second to local destinations when limited processing is applied (based on v7, December 2013). Even with remote destinations and more elaborate processing the performance is usually considered "stunning".

 RSYSLOG:
    Multi-threading
    TCP, SSL, TLS, RELP
    MySQL, PostgreSQL, Oracle and more
    Filter any part of syslog message
    Fully configurable output format
    Suitable for enterprise-class relay chains

13:47 2014-07-04
virtualization, docker
1, start docker daemon
> systemctl show docker | head -n 12
Id=docker.service
Names=docker.service
Requires=network.target basic.target
Wants=system.slice
Conflicts=shutdown.target
Before=shutdown.target
After=multi-user.target systemd-journald.socket basic.target system.slice
Description=Docker
LoadState=loaded
ActiveState=inactive
SubState=dead
> systemctl start docker
Failed to issue method call: Access denied
> sudo systemctl start docker
root's password:
> systemctl show docker | head -n 12
Id=docker.service
Names=docker.service
Requires=network.target basic.target
Wants=system.slice
Conflicts=shutdown.target
Before=shutdown.target
After=multi-user.target systemd-journald.socket basic.target system.slice
Description=Docker
LoadState=loaded
ActiveState=active
SubState=running
> ps -ef|grep docker
root      3554     1  0 13:47 ?        00:00:00 /usr/bin/docker -d

13:58 2014-07-04
software skill, zypper, non-interactive
        --non-interactive, -n   Do not ask anything, use default answers
                                automatically.
e.g. zypper -n in libvirt

16:06 2014-07-04
snapshot doc TODO
1, path: external snapshot file or dev path to new?
TODO: try it in libvirt qemu.
it is new. it is not the external snapshot file.
2, cover letter可以把我们的需求写的更迫切一些，恳切一些。

17:51 2014-07-04
bj-ha-3:/mnt/vm/bamvor # cat snapshot_ex.xml
<domainsnapshot>
  <description>Snapshot external test</description>
  <memory snapshot='external' file='/mnt/vm/bamvor/memory'/>
  <disks>
    <disk name='/mnt/vm/bamvor/disk0.qcow2' snapshot='external'>
      <driver type='qcow2'/>
      <source file='/mnt/vm/bamvor/disk0_new.qcow2'/>
    </disk>
  </disks>
</domainsnapshot>

bj-ha-3:/mnt/vm/bamvor # vim snapshot_ex.xml
bj-ha-3:/mnt/vm/bamvor # virsh snapshot-create cl8_n1_sles12b8_bjz snapshot_ex.xml
Domain snapshot 1404467157 created from 'snapshot_ex.xml'
bj-ha-3:/mnt/vm/bamvor # virsh list
 Id    Name                           State
----------------------------------------------------
 3     cl1_n1_sles12                  running
 4     cl8_n1_sles12b8                running
 5     clmd_n1_sles12                 running
 27    cl8_n1_sles12b8_bjz            running

bj-ha-3:/mnt/vm/bamvor # virsh dumpxml 27 | less
bj-ha-3:/mnt/vm/bamvor # ps -ef|grep qemu
root     27085     1  3 17:11 ?        00:01:08 /usr/bin/qemu-kvm -name cl8_n1_sles12b8_bjz -S -machine pc-i440fx-1.4,accel=kvm,usb=off -m 1024 -smp 1,sockets=1,cores=1,threads=1 -uuid 016db229-a046-26a8-3956-85c7fca5f96a -no-user-config -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/cl8_n1_sles12b8_bjz.monitor,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc -no-shutdown -device piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2 -drive file=/mnt/vm/bamvor/disk0.qcow2,if=none,id=drive-ide0-0-0,format=qcow2 -device ide-hd,bus=ide.0,unit=0,drive=drive-ide0-0-0,id=ide0-0-0,bootindex=1 -netdev tap,fd=25,id=hostnet0 -device rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:6f:d6:f1,bus=pci.0,addr=0x3 -netdev tap,fd=26,id=hostnet1 -device rtl8139,netdev=hostnet1,id=net1,mac=52:54:00:82:d4:da,bus=pci.0,addr=0x5 -vnc 0.0.0.0:3 -vga cirrus -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x4
root     28207 26515  0 17:46 pts/3    00:00:00 grep qemu
bj-ha-3:/mnt/vm/bamvor # ls
bjz.xml  disk0_new.qcow2  disk0.qcow2  disk0.raw  memory  snapshot_ex.xml
bj-ha-3:/mnt/vm/bamvor # qemu-img info disk0.qcow2
image: disk0.qcow2
file format: qcow2
virtual size: 10G (10737418240 bytes)
disk size: 974M
cluster_size: 65536
backing file: disk0.raw
Snapshot list:
ID        TAG                 VM SIZE                DATE       VM CLOCK
1         1404466193             851M 2014-07-04 17:29:53   00:18:08.509
bj-ha-3:/mnt/vm/bamvor # qemu-img info disk0_new.qcow2
image: disk0_new.qcow2
file format: qcow2
virtual size: 10G (10737418240 bytes)
disk size: 4.7M
cluster_size: 65536
backing file: /mnt/vm/bamvor/disk0.qcow2
backing file format: qcow2
bj-ha-3:/mnt/vm/bamvor #

08:12 2014-7-7
summary
live migration, lazy restore.

9:28 2014-7-7
software skill, misc, share mouse and keyboard
http://synergy-project.org

10:32 2014-07-07
GTD
0, 10:10

1, today
1), 10:33-11:37 13:21-15:46 send snapshot doc.
2), 11:37-12:35 lunch.
3), 12:35-13:16 software skill, "12:47 2014-07-07", "13:15 2014-07-07"
4), 20' discuss with dongmao about lvm. ref"16:19 2014-07-07"
5), 16:52-17:54 snapshot coding.

10:43 2014-07-07
snapshot, doc
git send-email * --no-chain-reply-to --annotate --to xen-devel@lists.xen.org --cc anthony.perard@citrix.com --cc ian.jackson@eu.citrix.com --cc ian.campbell@citrix.com --cc cyliu@suse.com --cc jfehlig@suse.com --cc zzhou@suse.com --cc hahn@univention.de --cc davidkiarie4@gmail.com --cc bjzhang@suse.com

12:47 2014-07-07
software skill, editor, vim, system clipboard: register *; X clipboard: register +
1, http://vim.wikia.com/wiki/Accessing_the_system_clipboard
Vim has extended vi to allow use of the * register as a reference to the system clipboard. So we can use normal mode commands like: "*dd or 1G"*yG to copy things into the * register and "*p to paste text from it.
2, "+" mean X clipboard.

13:15 2014-07-07
software skill, man page, man
1, "man apropos" to learn about a REALLY awesome program for searching through the manual pages.
2, man man
       -k, --apropos
              Equivalent to apropos.  Search the short manual page descriptions for keywords and display any matches.  See apropos(1) for details.

15:49 2014-07-07
virtualization, xen, arm
Stefano Stabellinim 20130731
http://lists.xen.org/archives/html/xen-devel/2013-07/msg02867.html
Considering that all guests, including dom0, run on xen on arm with
second stage translation enabled, it follows that without an IOMMU no
guests could actually drive the hardware.

The solution for platforms without an IOMMU is to use swiotlb-xen,
adapted to autotranslate guests. swiotlb-xen provides a set of dma_ops
that can be used by Linux to setup a contiguous buffer in stage-2
addresses and use it for dma operations.
Basically Linux asks Xen to make a buffer contiguous and gets the
machine address for it. This buffer is going to be used by lib/swiotlb.c
to allocate bounce buffers.

16:19 2014-07-07
software skill, storage, device mapper, lvm, dmsetup table
linux-bjrd:/home/bamvor # vgs
File descriptor 12 (socket:[335378]) leaked on vgs invocation. Parent PID 20125: bash
  VG      #PV #LV #SN Attr   VSize  VFree
  host      1   6   0 wz--n-  1.00t 513.00g
  system    2   2   0 wz--n- 31.26g      0
  system2   1   2   0 wz--n- 25.00g   6.00g
File descriptor 12 (socket:[335378]) leaked on vgchange invocation. Parent PID 20125: bash
  6 logical volume(s) in volume group "host" now active
linux-bjrd:/home/bamvor # dmsetup table
host-root: 0 104857600 linear 8:2 419432448
host-root_opensuse: 0 104857600 linear 8:2 629147648
host-migration_test: 0 20971520 linear 8:2 528484352
host-vm: 0 419430400 linear 8:2 734005248
host-home: 0 419430400 linear 8:2 2048
host-target: 0 2097152 linear 8:2 526387200

bamvor: meaning: name: ?? size linear major:minor start

16:54 2014-07-07
snapshot
1, libxl_disk_to_snapshot.
set or unset empty string in this function.
DONE
2, 现在就是external snapshot revert, 没有做，如果社区同意不做，就省事了。
3, create external snapshot时，xenstore和libxl-json里面的信息是否要修改??
最好是都修改了，但是不能影响系统运行。实在不行就修改一部分，但是输出配置文件应该是正确的。

08:30 2014-7-8
virtualization, notes
围绕cpu, timer/time, interrupt, memory, block, network, 介绍virsh和原理。

vcpu pin.

block: qemu data plane：多线程。性能regression, coroutine pool限制。

引出coroutine。进程，线程，coroutine。

10:28 2014-07-08
virtualization, colleague, alex graf, XNU
http://zh.wikipedia.org/wiki/XNU
XNU，由蘋果電腦發展的作業系統內核，被使用於Mac OS X中。它是Darwin作業系統的一部份，跟隨著Darwin一同作為自由及开放源代码软件被發布。XNU是X is Not Unix的縮寫。
歷史
XNU最早是NeXT公司為了NeXTSTEP作業系統而發展的。它是一種混合式核心（Hybrid kernel），結合了由卡內基美隆大學發展的Mach 2.5版，4.3BSD，與稱為Driver Kit的物件導向應用程式介面。
在蘋果電腦收購NeXT公司之後，XNU的Mach微內核被升級到Mach 3.0，BSD的部份升級至FreeBSD，Driver Kit則改成I/O Kit，一套以C++撰寫的應用程式介面。

13:55 2014-07-08
virtualization, docker, TODO
# docker images
REPOSITORY              TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
tutum/lamp              latest              664c09854881        12 days ago         477.6 MB
tutum/apache-php        latest              0e819813bc00        4 weeks ago         381.7 MB
mmckeen/opensuse-13-1   latest              6d441473953b        3 months ago        554.4 MB
# docker run -i -t -p 80 tutum/apache-php /bin/bash
root@54a0459717b9:/# ls
app  bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  run.sh  sbin  srv  start.sh  sys  tmp  usr  var
root@54a0459717b9:/# cd /app/
root@54a0459717b9:/app# ls
LICENSE  README.md  index.php  logo.png  phpinfo.php
root@54a0459717b9:/app# vi index.php
root@54a0459717b9:/app# cp -p index.php index1.php
root@54a0459717b9:/app# vi index1.php
root@54a0459717b9:/app# cd ..
root@54a0459717b9:/# ls
app  bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  run.sh  sbin  srv  start.sh  sys  tmp  usr  var
root@54a0459717b9:/# ./run
run/    run.sh
root@54a0459717b9:/# ./run
run/    run.sh
root@54a0459717b9:/# ./run.sh
/usr/lib/python2.7/dist-packages/supervisor/options.py:295: UserWarning: Supervisord is running as root and it is searching for its configuration file in default locations (including its current working directory); you probably want to specify a "-c" argument specifying an absolute path to a configuration file for improved security.
  'Supervisord is running as root and it is searching '
2014-07-08 05:48:38,422 CRIT Supervisor running as root (no user in config file)
2014-07-08 05:48:38,422 WARN Included extra file "/etc/supervisor/conf.d/supervisord-apache2.conf" during parsing
2014-07-08 05:48:38,488 INFO RPC interface 'supervisor' initialized
2014-07-08 05:48:38,489 CRIT Server 'unix_http_server' running without any HTTP authentication checking
2014-07-08 05:48:38,489 INFO supervisord started with pid 15
2014-07-08 05:48:39,499 INFO spawned: 'apache2' with pid 18
2014-07-08 05:48:40,758 INFO success: apache2 entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
^C2014-07-08 05:50:12,486 WARN received SIGINT indicating exit request
2014-07-08 05:50:12,498 INFO waiting for apache2 to die
2014-07-08 05:50:12,610 INFO stopped: apache2 (exit status 0)
root@54a0459717b9:/# exit
exit
# docker ps -a
CONTAINER ID        IMAGE                          COMMAND             CREATED             STATUS                      PORTS               NAMES
54a0459717b9        tutum/apache-php:latest        /bin/bash           3 minutes ago       Exited (0) 55 seconds ago                       stupefied_bell
f07314bc9bbc        mmckeen/opensuse-13-1:latest   /bin/bash           28 minutes ago      Up 26 minutes                                   loving_lalande
# docker commit 54a0459717b9 bjzhang/apache-php-test
b1adf742fecfdde1a2cc7d49826da7109425768f6187c42b4dc85b8010a7eb5a
# docker push bjzhang/apache-php-test
The push refers to a repository [bjzhang/apache-php-test] (len: 1)
Sending image list

Please login prior to push:
Username: your_docker_name
Password:
Email: your_docker_email
Login Succeeded
The push refers to a repository [bjzhang/apache-php-test] (len: 1)
Sending image list
Pushing repository bjzhang/apache-php-test (1 tags)
511136ea3c5a: Image already pushed, skipping
35f6dd4dd141: Image already pushed, skipping
7baf0ef6f14a: Image already pushed, skipping
e497c7c1bfbb: Image already pushed, skipping
5cf8fd909c6c: Image already pushed, skipping
06ec8d249ba4: Image already pushed, skipping
fd3b9630d4f1: Image already pushed, skipping
dc4df1c2dd56: Image already pushed, skipping
fb7a77729a38: Image already pushed, skipping
0bef2ebda68b: Image already pushed, skipping
6aa3274afcdf: Image already pushed, skipping
645570f4e1f5: Image already pushed, skipping
0d5949248d0b: Image already pushed, skipping
666319e69f93: Image already pushed, skipping
ca0611f2e87c: Image already pushed, skipping
bc9d13a2676c: Image already pushed, skipping
0e819813bc00: Image already pushed, skipping
b1adf742fecf: Image successfully pushed
Pushing tag for rev [b1adf742fecf] on {https://registry-1.docker.io/v1/repositories/bjzhang/apache-php-test/tags/latest}
#

16:22 2014-07-08
linux-bjrd:~ # virsh vcpuinfo 3
VCPU:           0
CPU:            2
State:          running
CPU time:       0.3s
CPU Affinity:   yyyyyyyy

VCPU:           1
CPU:            1
State:          running
CPU time:       0.3s
CPU Affinity:   yyyyyyyy

VCPU:           2
CPU:            2
State:          running
CPU time:       0.3s
CPU Affinity:   yyyyyyyy

VCPU:           3
CPU:            0
State:          running
CPU time:       0.4s
CPU Affinity:   yyyyyyyy

linux-bjrd:~ # cat /proc/cpuinfo | less
linux-bjrd:~ # virsh help|grep vcpu
    maxvcpus                       connection vcpu maximum
    setvcpus                       change number of virtual CPUs
    vcpucount                      domain vcpu counts
    vcpuinfo                       detailed domain vcpu information
    vcpupin                        control or query domain vcpu affinity
linux-bjrd:~ # virsh vcpupin 3 0 0

linux-bjrd:~ # virsh vcpuinfo 3
VCPU:           0
CPU:            0
State:          running
CPU time:       0.3s
CPU Affinity:   y-------

VCPU:           1
CPU:            1
State:          running
CPU time:       0.3s
CPU Affinity:   yyyyyyyy

VCPU:           2
CPU:            3
State:          running
CPU time:       0.3s
CPU Affinity:   yyyyyyyy

VCPU:           3
CPU:            0
State:          running
CPU time:       0.4s
CPU Affinity:   yyyyyyyy

17:12 2014-07-08
virtualization, xen, hap, ept, npt
1, http://wiki.xenproject.org/wiki/Xen_Common_Problems#How_can_I_check_if_my_CPU_supports_HAP_.28Hardware_Assisted_Paging.29_.3F
 How can I check if my CPU supports HAP (Hardware Assisted Paging) ?

You can check Xen dmesg by running "xl dmesg" to verify if HAP is supported on your CPU:

(XEN) HVM: Hardware Assisted Paging detected and enabled.

Newer Xen versions (4.1.3+, 4.2.x+) will have info like this:

(XEN) HVM: Hardware Assisted Paging (HAP) detected
(XEN) HVM: HAP page sizes: 4kB, 2MB

HAP support is provided by the following features on CPUs:

    Intel EPT (Extended Page Tables).
    AMD NPT (Nested Page Tables, sometimes also called as AMD RVI - Rapid Virtualization Indexing).

2, include/asm-x86/hvm/vmx/vmx.h
typedef union {
    struct {
        u64 r       :   1,  /* bit 0 - Read permission */
        w           :   1,  /* bit 1 - Write permission */
        x           :   1,  /* bit 2 - Execute permission */
        emt         :   3,  /* bits 5:3 - EPT Memory type */
        ipat        :   1,  /* bit 6 - Ignore PAT memory type */
        sp          :   1,  /* bit 7 - Is this a superpage? */
        rsvd1       :   2,  /* bits 9:8 - Reserved for future use */
        recalc      :   1,  /* bit 10 - Software available 1 */
        snp         :   1,  /* bit 11 - VT-d snoop control in shared
                               EPT/VT-d usage */
        mfn         :   40, /* bits 51:12 - Machine physical frame number */
        sa_p2mt     :   6,  /* bits 57:52 - Software available 2 */
        access      :   4,  /* bits 61:58 - p2m_access_t */
        tm          :   1,  /* bit 62 - VT-d transient-mapping hint in
                               shared EPT/VT-d usage */
        avail3      :   1;  /* bit 63 - Software available 3 */
    };
    u64 epte;
} ept_entry_t;

08:44 2014-07-09
GTD
1, today
1), 40' sync.

2, next
1), coding excise
(1),
disk = snapshot[i].disk[i];
(2), time
localtime_r((time_t*)&snapshot[i].creation_time, &time_info);
strftime(timestr, sizeof(timestr), "%Y-%m-%d %H:%M:%S %z", &time_info);
(3), 2d, 3d pointer.

16:17 2014-07-10
GTD
1, today
1), 16:17 snapshot.

17:47 2014-07-10
snapshot
1, TODO
need to write similar function like DEVICE_ADD_JSON and  DEVICE_REMOVE_JSON in order to change one attribute on json.

18:06 2014-7-10
time, ntp.suse.de

11:37 2014-07-11
snapshot, discuss with Chunyan
1, HVM, PV中qemu disk是否有区别。
2, domain snapshot
memory只有yes, no, 绝对路径。和libvirt里面是yes+external+file, yes+internal. 对于libxl来说，没有internal(qemu的internal是写到第一个disk(支持internal disk snapshot), 就是vm state size).

13:01 2014-07-11
virtualization, libvirt, kvm, migraiton, bnc#885811
[Bug 885811] libvirt for kvm: Filesystem was mounted as readonly after migration
-- Comment #8 from James Fehlig <jfehlig@suse.com> 2014-07-10 20:59:24 UTC ---
(In reply to comment #5)
> I figured out the key of how to reproduce the bug:
> Make sure the guest is based on LOCAL storage on source host, export it by nfs,
> and it is mounted on target host.

That's not a valid configuration and can cause all sorts of problems.  The
image is essentially being accessed by the source and target hosts through
different filesystems.  On the source host, it is accessed through the local fs
type (btrfs I presume).  On the target host, it is accessed through nfs.  That
could cause all sorts of grief when both are changing ownership, etc.  It also
prevents using a lock manager like lockd that does flock() on the image.
flock() doesn't work across filesystems :-).

I suppose you might get this to work if you set

user = "root"
group = "root"
dynamic_ownership = 0

in /etc/libvirt/qemu.conf.  Out of curiosity, does it work with those settings?
 Either way, I don't want to spend too much time looking at this since IMO it
is not a valid setup.

15:35 2014-07-11
https://github.com/bjzhang/xen
git://xenbits.xen.org/people/liuw/xen.git snapshot_20140710__base_on_weiliu9

16:10 2014-07-11
software skill, SCM, git, clone, retrieve submobule when git clone
   --recursive, --recurse-submodules
       After the clone is created, initialize all submodules within, using their default
       settings. This is equivalent to running git submodule update --init --recursive
       immediately after the clone is finished. This option is ignored if the cloned repository
       does not have a worktree/checkout (i.e. if any of --no-checkout/-n, --bare, or --mirror is
       given)

22:58 2014-07-11
(22:43 2014-07-14)
1, ian C
Hi, Ian

thanks your reply. your suggestion is very important for me. meanwhile i am
not sure i could follow you all the time. please correct me, thanks.
> On Mon, 2014-07-07 at 15:46 +0800, Bamvor Jian Zhang wrote:
> > Libxl Domain Snapshot API Design
>
> Thanks for splitting the libxl layer into a separate document. I think
> it is useful to consider this bit first in isolation before getting hung
> up on how xl might make use of it.
>
> > 1. New Structures
> >
> >     Domain snapshot introduces two new structures:
> >     - "libxl_domain_snapshot" store domain snapshot information, it contains
> >        libxl_disk_snapshot array.
> >     - "libxl_disk_snapshot" stores disk snapshot related information.
>
> >     Struct Details:
> >
> >     libxl_disk_snapshot = Struct("disk_snapshot",[
>
> I wonder if this should incorporate a libxl_device_disk (either inline
> or by reference), or perhaps even simply merged into the disk struct.
>
> I think this would remove the need for the device, file, format and path
> fields and be more logical IMHO.
yes, embedded the libxl_device_disk into libxl_disk_snapshot may be useful
for some logic, e.g. check whether the disk could snaphot, readonly or cdrom
do not support snapshot.
meanwhile for the external snapshot, there are two pdev_path: the one is the
disk path before snapshot, the other is disk path after external snapshot.
functions relative to external snapshot may not use the both pdev_path at
the same time, but it seems more clear if we have two pdev_path.
and there is a additional format for the new disk path above. So, the
libxl_disk_snapshot would be:
     libxl_disk_snapshot = Struct("disk_snapshot",[
        ("name",          string),                /* The name of disk snapshot. */
        ("type",          libxl_snapshot_format), /* snapshot type: internal,
                                                   * external
                                                   */
        ("pdev_path_new", string),),              /* The new disk file after
                                                    * external snapshot. empty for
                                                   * internal snapshot.
                                                   */
        ("format_new",    libxl_disk_format),     /* The format of external
                                                   * snapshot
                                                   */
        ("disk",          libxl_device_disk),
        ])

>
>
> >         ("device",        string),              /* The name of disk: hda, hdc */
> >
> >         ("name",          string),              /* The name of disk snapshot.
> >                                                  * Usually it is inherited from
> >                                                  * libxl_domain_snapshot.
> >                                                  */
> >
> >         ("file",          string),              /* The new disk file after
> >                                                  * external snapshot. empty for
> >                                                  * internal snapshot.
> >                                                  */
> >
> >         ("format",        libxl_disk_format),   /* The format of external
> >                                                  * snapshot file. For the
> >                                                  * internal snapshot, it's
> >                                                  * ignored and it should be
> >                                                  * LIBXL_DISK_FORMAT_UNKNOWN
> >                                                  */
> >
> >         ("path",          string),              /* The path of current disk
> >                                                  * backend. It gets from
> >                                                  * libxl_device_disk_getinfo.
> >                                                  * It will be force-empty when
> >                                                  * store domain snapshot
> >                                                  * configuration in order to
> >                                                  * hide this from users.
> >                                                  */
> >         ])
> >
> >     libxl_domain_snapshot = Struct("domain_snapshot",[
> >         ("name",          string),              /* The name of the domain
> >                                                  * snapshot. It should not be
> >                                                  * empty.
> >                                                  */
> >
> >         ("description",   string),              /* The description of snapshot.
> >                                                  * It could be empty.
> >                                                  */
> >
> >         ("creation_time", uint64),              /* The creation time of domain
> >                                                  * snapshot which is the epoch
> >                                                  * second from 1, Jan 1970.
> >                                                  */
> >
> >         ("memory",        string),              /* The path to save domain
> >                                                  * memory image. 'empty' means
> >                                                  * it is a disk-only snapshot.
> >                                                  * note that "yes" or "no" is
> >                                                  * not allowed, this is different
> >                                                  * from xl.snapshot.pod.5
>
> Encoding all of that into a string with some strings having magic
> properties isn't the right design.
>
> This should be a defbool or a bool indicating whether or not memory is
> included and a separate string which is the path if it is included.
i will change it in docs/man/xl.snapshot.pod.5
for the libxl_domain_snapshot, the memory attribute only support absolute path
of memory image.
>
> >         /* Following state represents the domain state in the beginning of snapshot.
> >          * These state gets from libxl_domain_info.
>
> What is this used for?
recording the state of domain while take the snapshot. basically, i add it because
libvirt need track the domain state: running or paused.
maybe i should record the above two state directly?
(running in libvirt means running or blocked in libxl).
>
> >          */
> >         ("running",       bool),
> >         ("blocked",       bool),
> >         ("paused",        bool),
> >         ("shutdown",      bool),
> >         ("dying",         bool),
> >
> >         /* The array of disk snapshot information belong to this domain snapshot. */
> >         ("disks", Array(libxl_disk_snapshot, "num_disks")),
> >         ])
> >
> >
> > 2. New Functions
> >
> >   2.1 Management functions for domain snapshot config file (libxl-json format).
> >
> >     /* There are two type of config file relative to domain snapshot: user
> >      * config file and internal domain snapshot configuration file(libxl-json
> >      * format). The relation of the two config files are like xl.cfg and
> >      * libxl-json for domain configuration.
> >      * The user visiable config file (KEY=VALUE format) is only used for
> >      * creation. The internal domain snapshot config file is located at
> >      * "/var/lib/xen/snapshots/<domain_uuid>"\
> >      * snapshotdata-<snapshot_name>.libxl-json". This file is only for internal
> >      * usage, not for users. user should not modify the libxl-json format file.
> >      *
> >      * Currently, libvirt use XML format snapshot configuration file for user
> >      * both input(snapshot create) and output(snapshot-dumpxml). And libvirt
> >      * qemu driver store with xml format as internal usage as well.
> >      * For libxl, if libxl hope it is easy to migrate domain between different
> >      * toolstack, then all the toolstack should use the same internal config
> >      * file: libxl-json format. it will not affect the user experience. e.g. xl
> >      * will use the KEY=VALUE format while libvirt will use the xml format.
> >      */
>
> There is a bunch of stuff here which IMHO does not belong in the libxl
> API. In general libxl should be providing the mechanisms for doing
> things but the policies and management (i.e. where to save things,
> listing, deleting etc) belong in the application.
agree. i should move it the other document.
>
> So all of the stuff to do with config file parsing and specification of
> paths where things should be stored are issues for the toolstack and not
> libxl. i.e. I'm sure libvirt has its own ideas about these things
> already, which we should use, and I would expect things like the
> location for the disk snapshots to be passed to xl snapshot somehow.
>
> AFAICT the libxl API should be
>     libxl_domain_snapshot_save(libxl_ctx *ctx, uint32_t domid,
>                 const char *name, libxl_domain_snapshot *snapshot)
>
> Which should take a snapshot of domain domid using parameters from the
> snapshot object and update snapshot with the specifics.
yes, this is the issue i want to discuss. i write it in 4/5. sorry for
confuse.
Q: Why there is no universe API for domain snapshot?
A: This is my initial target while working on snapshot. with the common API,
   different toolstack(xl or libvirt) could call the same api for the same
   operation. life would be eaiser compare to the domain create, restore and
   ...

   The reason why I could not provide common API is that it is hard to handle
   the ao things in api. e.g. in domain snapshot create, libvirt may wait the
   memory save by waiting the ao complete flag.

   Another reason is that I could share more functions in xl command
   with xl snapshot command if i do not need to provide the common api. share
   the code mean easy to maintenance.
> The caller would
> have to supply any necessary paths etc in the snapshot object. It might
> be better to split libxl_domain_snapshot onto two, one representing the
> parameters for a snapshot and one representing the resulting snapshot.
>
> libxl shouldn't be doing anything with parsing json objects, storing
> snapshot config files or picking/mandating the output paths or anything
> like that.
yes, i agree that libxl should not picking/mandating the output paths. it
should be determined by application. currently, in my code, all the paths
is get from user config file or generated by xl not libxl.
>
> Of course the application might choose to make use of the very
> convenient libxl functions for converting libxl structs to/from json.
> libvirt has an XML config format already, there is no reason not to use
> it in that context.
yes, libvirt use the XML config. i provide the load/store json config api
in order to migrate between xl and libvirt. what i mean is that when libvirt
libxl driver load/reload, it could get the snapshot created by libxl through
libxl_list_dom_snapshot.
if libvirt libxl driver could record the snapshot configuration with both
XML and libxl-json(through libxl_store_dom_snapshot_conf) format. then xl
could easily access the snapshot state created by libvirt libxl driver.
>
> Likewise on snapshot restore (or revert):
>     libxl_domain_snapshot_restore(ctx, libxl_domain_snapshot *snapshot,
>                                   *r_domid)
> should take the snapshot and make a new domain out of it. (someone would
> need to specify what happens if another domain exists already in that
> snapshot chain etc).
i need to think about it. generally, if we add the
libxl_domain_snapshot_restore api, i need to think about how to expose the
ao_how to the application for more than one stage. i mean i need ao_complete
twice: the first is after i call disk_revert(qemu-img). the second is after
memory restore. is there some existence code or document show me how to do it?
>
> Any management of sets of snapshots, paths to be saving them in,
> listing, deleting etc is down to the application.
>
>
> >   2.2 functions for disk snapshot operations
>
> Do these need to be exposed separately? You lbixl_domain_snapshot struct
> already has a mechanism for indicating whether memory should be included
> in the snapshot, so aren't all these functions equiavalent to the
> domain_snapshot ones but with memory=no?
the reasone why there are disk snapshot opration is there is no domain
snapshot operation(at least create, revert) in my current design. if we
could provide the domain snapshot operation, there is no need to expose
current disk snapshot operation.
>
> Anyway, if you think these are necessary then I think the same general
> comments apply. libxl should be providing a mechanism for taking a
> snapshot into an application provided location. But the application is
> responsible for managing them, listing them, deciding where they should
> live etc.
understand.

thanks

bamvor
>
> Ian.
>
2), reply to Ian I
(the following message is not sent)
Hi, Ian

thanks your reply. your suggestion is very important for me.

(the following message is not sent)end

2, reply to Ian J
> Ian Campbell writes ("Re: [RFC V5 2/5] Libxl Domain Snapshot API Design"):
> > On Mon, 2014-07-07 at 15:46 +0800, Bamvor Jian Zhang wrote:
> ...
> > >         ("memory",        string),       /* The path to save domain
> > >                                           * memory image. 'empty' means
> > >                                           * it is a disk-only snapshot.
> > >                                           * note that "yes" or "no" is
> > >                                           * not allowed, this is different
> > >                                           * from xl.snapshot.pod.5
>
Hi, Ian
> As I wrote on IRC:
sorry, i forget logging out my irc when i leave company.
>
> I still don't really understand how the distinction between snapshots
> with memory=yes and memory=no is supposed to operate.  Is it that if
> you take a snapshot of a running domain with memory=no, and then later
> resume it, it is as if the guest had crashed at the time of the
> snapshot ?  (How does this interact with disk IO barriers?)
yes, as you said, the domain may crash after disk stae resume if
there is no memory state resume.
basically, this is compatible with libvirt domain snapshot, ref[1].
after read the libvirt and qemu code again, i found that there is a cpu
stop qmp before create disk only snapshot when domain is running. such
qmp will call bdrv_drain_all and bdrv_flush_all for flush all data to
disk.
compare to libxl, in my current code, i call libxl_domain_pause before
creating disk only snapshot. it seems that libxl_domain_pause cause the
vcpu stop through hypercall. and i do not see the similar flush date to
disk operation along with vcpus stop.
how should i deal with it? could i call stop cpu qmp after
libxl_domain_pause in order to flush data to disk?
>
> I think the semantics should be spelled out somewhere.
>
> (Also I assume that a memory snapshot isn't available unless there's a
> running domain, but that also needs to be specified.)
yes, definitely. i will add this to the document.
regards 
bamvor

[1] http://libvirt.org/formatsnapshot.html
>
> Thanks,
> Ian.
>

23:19 2014-07-11
libvirt qemu support revert external snapshot.
cover letter
https://www.redhat.com/archives/libvir-list/2012-October/msg01290.html
revert external snapshot
https://www.redhat.com/archives/libvir-list/2012-October/msg01310.html

22:43 2014-07-14
GTD
1, today
1), 30' write virtualization summary.
2), 1h snapshot: reply to Ian C. see"22:58 2014-07-11"

21:28 2014-07-15
1,
Hi, Ian
> On Mon, 2014-07-14 at 08:42 -0600, Bamvor Jian Zhang wrote:
> > Hi, Ian
> >
> > thanks your reply. your suggestion is very important for me. meanwhile i am
> > not sure i could follow you all the time. please correct me, thanks.
> > > On Mon, 2014-07-07 at 15:46 +0800, Bamvor Jian Zhang wrote:
> > > > Libxl Domain Snapshot API Design
> > >
> > > Thanks for splitting the libxl layer into a separate document. I think
> > > it is useful to consider this bit first in isolation before getting hung
> > > up on how xl might make use of it.
> > >
> > > > 1. New Structures
> > > >
> > > >     Domain snapshot introduces two new structures:
> > > >     - "libxl_domain_snapshot" store domain snapshot information, it contains
> > > >        libxl_disk_snapshot array.
> > > >     - "libxl_disk_snapshot" stores disk snapshot related information.
> > >
> > > >     Struct Details:
> > > >
> > > >     libxl_disk_snapshot = Struct("disk_snapshot",[
> > >
> > > I wonder if this should incorporate a libxl_device_disk (either inline
> > > or by reference), or perhaps even simply merged into the disk struct.
> > >
> > > I think this would remove the need for the device, file, format and path
> > > fields and be more logical IMHO.
> > yes, embedded the libxl_device_disk into libxl_disk_snapshot may be useful
> > for some logic, e.g. check whether the disk could snaphot, readonly or cdrom
> > do not support snapshot.
> > meanwhile for the external snapshot, there are two pdev_path: the one is the
> > disk path before snapshot, the other is disk path after external snapshot.
> > functions relative to external snapshot may not use the both pdev_path at
> > the same time, but it seems more clear if we have two pdev_path.
> > and there is a additional format for the new disk path above.
>
> Perhaps what you want is two libxl_device_disk fields then, parent and
> child?
yes.
>
> Or looking at it another way the input to a disk snapshot operation
> would be a libxl_device_disk and some options and the output would be
> another, different, libxl_device_disk.
Understand. There are two issues:
1. If i use the libxl_device_disk, the old path(before external snapshot)
is missing. This will be inconvenient if we revert the external snapshot.
2. When toolstack save the domain snapshot configuration file
(libxl-json), this configuration is longer than use libxl_disk_snapshot.
e.g. the libxl_device_disk output:
    "disks": [
        {
            "backend_domid": 0,
            "backend_domname": null,
            "pdev_path": "/var/lib/xen/snapshots/5c84adcc-bd59-788a-96d2-195f9b599cfe/disk_hda.qcow2",
            "vdev": "hda",
            "format": "qcow2",
            "script": null,
            "removable": 0,
            "readwrite": 1,
            "is_cdrom": 0,
            "direct_io_safe": false
        },
        ...
libxl_disk_snapshot output:
    "disks": [
        {
            "device": "hda",
            "name": "external snapshot 20140710",
            "file": "/var/lib/xen/snapshots/5c84adcc-bd59-788a-96d2-195f9b599cfe/disk_hda.qcow2",
            "format": "qcow2",
            "path": "",
            "type": "external"
        },
>
> > >
> > >
> > > >         ("device",        string),              /* The name of disk: hda, hdc */
> > > >
> > > >         ("name",          string),              /* The name of disk snapshot.
> > > >                                                  * Usually it is inherited from
> > > >                                                  * libxl_domain_snapshot.
> > > >                                                  */
> > > >
> > > >         ("file",          string),              /* The new disk file after
> > > >                                                  * external snapshot. empty for
> > > >                                                  * internal snapshot.
> > > >                                                  */
> > > >
> > > >         ("format",        libxl_disk_format),   /* The format of external
> > > >                                                  * snapshot file. For the
> > > >                                                  * internal snapshot, it's
> > > >                                                  * ignored and it should be
> > > >                                                  * LIBXL_DISK_FORMAT_UNKNOWN
> > > >                                                  */
> > > >
> > > >         ("path",          string),              /* The path of current disk
> > > >                                                  * backend. It gets from
> > > >                                                  * libxl_device_disk_getinfo.
> > > >                                                  * It will be force-empty when
> > > >                                                  * store domain snapshot
> > > >                                                  * configuration in order to
> > > >                                                  * hide this from users.
> > > >                                                  */
> > > >         ])
> > > >
> > > >     libxl_domain_snapshot = Struct("domain_snapshot",[
> > > >         ("name",          string),              /* The name of the domain
> > > >                                                  * snapshot. It should not be
> > > >                                                  * empty.
> > > >                                                  */
> > > >
> > > >         ("description",   string),              /* The description of snapshot.
> > > >                                                  * It could be empty.
> > > >                                                  */
> > > >
> > > >         ("creation_time", uint64),              /* The creation time of domain
> > > >                                                  * snapshot which is the epoch
> > > >                                                  * second from 1, Jan 1970.
> > > >                                                  */
> > > >
> > > >         ("memory",        string),              /* The path to save domain
> > > >                                                  * memory image. 'empty' means
> > > >                                                  * it is a disk-only snapshot.
> > > >                                                  * note that "yes" or "no" is
> > > >                                                  * not allowed, this is different
> > > >                                                  * from xl.snapshot.pod.5
> > >
> > > Encoding all of that into a string with some strings having magic
> > > properties isn't the right design.
> > >
> > > This should be a defbool or a bool indicating whether or not memory is
> > > included and a separate string which is the path if it is included.
> > i will change it in docs/man/xl.snapshot.pod.5
>
> My question was about the libxl interface given here, not xl so I don't
> think updating xl.snapshot.pod is going to be helpful.
>
> (note that I was querying because of the use of "empty" as something
> magic, not because of the comment about xl.snapshot)
got it. i will add bool.
>
> > >
> > > >         /* Following state represents the domain state in the beginning of snapshot.
> > > >          * These state gets from libxl_domain_info.
> > >
> > > What is this used for?
> > recording the state of domain while take the snapshot. basically, i add it because
> > libvirt need track the domain state: running or paused.
> > maybe i should record the above two state directly?
>
> I think so. I think you also need to state clearly what the expected
> semantics are. e.g. does "paused" incorporate I/O quiesced?
After think about it, at least i need active and inactive state. The active
allow domain snapshot and disk-only snapshot. The inactive state only allow
the disk-only snapshot.
Meanwhile i am not suse if i need the paused state. Libvirt qemu driver record
this state. I guess it is because qemu will flush all io to disk when domain
paused. This may be useful for user to know the exactly disk status. e.g., if
user create a disk snapshot when domain paused, the disk state should be
coherent.
But i do not find the libxl do the similar flush operation for pause.
> > >
> > > So all of the stuff to do with config file parsing and specification of
> > > paths where things should be stored are issues for the toolstack and not
> > > libxl. i.e. I'm sure libvirt has its own ideas about these things
> > > already, which we should use, and I would expect things like the
> > > location for the disk snapshots to be passed to xl snapshot somehow.
> > >
> > > AFAICT the libxl API should be
> > >     libxl_domain_snapshot_save(libxl_ctx *ctx, uint32_t domid,
> > >                 const char *name, libxl_domain_snapshot *snapshot)
> > >
> > > Which should take a snapshot of domain domid using parameters from the
> > > snapshot object and update snapshot with the specifics.
> > yes, this is the issue i want to discuss. i write it in 4/5. sorry for
> > confuse.
>
> I'm afraid I don't understand what you are trying to say with this Q+A.
>
> > Q: Why there is no universe API for domain snapshot?
> > A: This is my initial target while working on snapshot. with the common API,
> >    different toolstack(xl or libvirt) could call the same api for the same
> >    operation. life would be eaiser compare to the domain create, restore and
>
> easier in what sense?
>
> >    ...
> >
> >    The reason why I could not provide common API is that it is hard to handle
> >    the ao things in api. e.g. in domain snapshot create, libvirt may wait the
> >    memory save by waiting the ao complete flag.
>
> The libxl API almost certainly does need to be async and use ao_how etc.
> That's pretty much unavoidable.
>
> I'm also confused because it appeared to me that what I was commenting
> on was a common API, but here you say you cannot provide that.
>
> >    Another reason is that I could share more functions in xl command
> >    with xl snapshot command if i do not need to provide the common api. share
> >    the code mean easy to maintenance.
>
> share with what?
e.g. share the create_domain functions in tools/libxl/xl_cmdimpl.c for domain
revert.
>
> Sorry, I'm totally confused about what you are trying to say in this
> entire section.
>
> > > The caller would
> > > have to supply any necessary paths etc in the snapshot object. It might
> > > be better to split libxl_domain_snapshot onto two, one representing the
> > > parameters for a snapshot and one representing the resulting snapshot.
> > >
> > > libxl shouldn't be doing anything with parsing json objects, storing
> > > snapshot config files or picking/mandating the output paths or anything
> > > like that.
> > yes, i agree that libxl should not picking/mandating the output paths. it
> > should be determined by application. currently, in my code, all the paths
> > is get from user config file or generated by xl not libxl.
>
> If that is the case then I'm afraid that this document does not reflect
> that reality.
i will update the document.
>
> > > Of course the application might choose to make use of the very
> > > convenient libxl functions for converting libxl structs to/from json.
> > > libvirt has an XML config format already, there is no reason not to use
> > > it in that context.
> > yes, libvirt use the XML config. i provide the load/store json config api
> > in order to migrate between xl and libvirt. what i mean is that when libvirt
> > libxl driver load/reload, it could get the snapshot created by libxl through
> > libxl_list_dom_snapshot.
> > if libvirt libxl driver could record the snapshot configuration with both
> > XML and libxl-json(through libxl_store_dom_snapshot_conf) format. then xl
> > could easily access the snapshot state created by libvirt libxl driver.
>
> I don't think "portability" of snapshots in this way is required and it
> is making your API more complex than it needs to be IMHO.
>
> It is fine and expected that xl and libvirt snapshots are manageable
> only by the toolstack which creates them.
ok.
>
> > > Likewise on snapshot restore (or revert):
> > >     libxl_domain_snapshot_restore(ctx, libxl_domain_snapshot *snapshot,
> > >                                   *r_domid)
> > > should take the snapshot and make a new domain out of it. (someone would
> > > need to specify what happens if another domain exists already in that
> > > snapshot chain etc).
> > i need to think about it. generally, if we add the
> > libxl_domain_snapshot_restore api, i need to think about how to expose the
> > ao_how to the application for more than one stage. i mean i need ao_complete
> > twice: the first is after i call disk_revert(qemu-img). the second is after
> > memory restore. is there some existence code or document show me how to do it?
>
> Why do you need to ao complete twice? The ao should complete once at the
> end of the aggregate operation.

When I wrote this version, I though there are two things time consuming,
one is disk snapshot apply (that may call 'qemu-img' to do the work), the
other is memory restore. And I thought these two should be one after another,
so to avoid waiting qemu-img completion, we might need an ao operation,
and in its ao_complete, call next stage work (memory restore).

Now thinking it again, yes, I think one ao could be OK. The two work should
be independent, then we can simply do them parallelly, so don't need a separate
ao operation for qemu-img work completion. In this way, one ao is enough.

>
> If what you want is a progress indication then perhaps the interface
> needs to take one or more libxl_asyncprogress_how objects to describe
> those stages. Domain create uses this to notify when the console is
> ready for example.
>
> > >
> > > Any management of sets of snapshots, paths to be saving them in,
> > > listing, deleting etc is down to the application.
> > >
> > >
> > > >   2.2 functions for disk snapshot operations
> > >
> > > Do these need to be exposed separately? You lbixl_domain_snapshot struct
> > > already has a mechanism for indicating whether memory should be included
> > > in the snapshot, so aren't all these functions equiavalent to the
> > > domain_snapshot ones but with memory=no?
> > the reasone why there are disk snapshot opration is there is no domain
> > snapshot operation(at least create, revert) in my current design. if we
> > could provide the domain snapshot operation, there is no need to expose
> > current disk snapshot operation.
>
> Why don't you provide a domain snapshot operation? I thought that was
> the whole point of this new interface.
>
> Ian.
>

2,
> On Wed, 2014-07-16 at 03:27 -0600, Bamvor Jian Zhang wrote:
> > > Or looking at it another way the input to a disk snapshot operation
> > > would be a libxl_device_disk and some options and the output would be
> > > another, different, libxl_device_disk.
> > Understand. There are two issues:
> > 1. If i use the libxl_device_disk, the old path(before external snapshot)
> > is missing. This will be inconvenient if we revert the external snapshot.
>
> I don't follow. Surely the old path is the path of the already existing
> disk which you are taking a snapshot of?
I mean the old path could not be retrieved from any struct. Both
libxl_device_disk and libxl_domain_snapshot has no old path info.
Then to do external snapshot apply, we may have to get the backing file
from qemu-img|qmp output. It is a little bit inconvenient.
>
> > 2. When toolstack save the domain snapshot configuration file
> > (libxl-json), this configuration is longer than use libxl_disk_snapshot.
> > e.g. the libxl_device_disk output:
>
> But it fully describes everything you would need to attach it to a
> guest, doesn't it? Isn't that a good thing?
It is good for me. I just wondering if you think it is too long.
>
> > >
> > > > >
> > > > > >         /* Following state represents the domain state in the beginning of snapshot.
> > > > > >          * These state gets from libxl_domain_info.
> > > > >
> > > > > What is this used for?
> > > > recording the state of domain while take the snapshot. basically, i add it because
> > > > libvirt need track the domain state: running or paused.
> > > > maybe i should record the above two state directly?
> > >
> > > I think so. I think you also need to state clearly what the expected
> > > semantics are. e.g. does "paused" incorporate I/O quiesced?
> > After think about it, at least i need active and inactive state. The active
> > allow domain snapshot and disk-only snapshot. The inactive state only allow
> > the disk-only snapshot.
>
> What do active and inactive mean? Paused? I/O Quiesced? Shutdown?
'Active' means running or paused. 'Inactive' means shutdown.
>
> > Meanwhile i am not suse if i need the paused state. Libvirt qemu driver record
> > this state. I guess it is because qemu will flush all io to disk when domain
> > paused. This may be useful for user to know the exactly disk status. e.g., if
> > user create a disk snapshot when domain paused, the disk state should be
> > coherent.
>
> Not necessarily, if you paused while the guest was halfway through a
> journal update and do a snapshot with no memory then you would end up
> recovering the journal when you next mount the filesystem. That's
> different from quiescing I/O which requires a guest agent AFAIK.
>
> > But i do not find the libxl do the similar flush operation for pause.
>
> Correct, AFAIK.
>
> > > >    ...
> > > >
> > > >    The reason why I could not provide common API is that it is hard to handle
> > > >    the ao things in api. e.g. in domain snapshot create, libvirt may wait the
> > > >    memory save by waiting the ao complete flag.
> > >
> > > The libxl API almost certainly does need to be async and use ao_how etc.
> > > That's pretty much unavoidable.
> > >
> > > I'm also confused because it appeared to me that what I was commenting
> > > on was a common API, but here you say you cannot provide that.
> > >
> > > >    Another reason is that I could share more functions in xl command
> > > >    with xl snapshot command if i do not need to provide the common api. share
> > > >    the code mean easy to maintenance.
> > >
> > > share with what?
> > e.g. share the create_domain functions in tools/libxl/xl_cmdimpl.c for domain
> > revert.
>
> I think this is of secondary concern to having a useful and correct
> libxl level API.
>
> I'm still not sure what the "common API" you are referring to is. What
> function exactly are you proposing to make common or conversely which
> functions do you think it is not possible to make common?
There is no domain snapshot level api in my original proposal. And after
discussing with you, I feel that i could provide the API like:
libxl_domain_snapshot_create, libxl_domain_snapshot_restore
>
>
> > > > > Likewise on snapshot restore (or revert):
> > > > >     libxl_domain_snapshot_restore(ctx, libxl_domain_snapshot *snapshot,
> > > > >                                   *r_domid)
> > > > > should take the snapshot and make a new domain out of it. (someone would
> > > > > need to specify what happens if another domain exists already in that
> > > > > snapshot chain etc).
> > > > i need to think about it. generally, if we add the
> > > > libxl_domain_snapshot_restore api, i need to think about how to expose the
> > > > ao_how to the application for more than one stage. i mean i need ao_complete
> > > > twice: the first is after i call disk_revert(qemu-img). the second is after
> > > > memory restore. is there some existence code or document show me how to do it?
> > >
> > > Why do you need to ao complete twice? The ao should complete once at the
> > > end of the aggregate operation.
> >
> > When I wrote this version, I though there are two things time consuming,
> > one is disk snapshot apply (that may call 'qemu-img' to do the work), the
> > other is memory restore. And I thought these two should be one after another,
> > so to avoid waiting qemu-img completion, we might need an ao operation,
> > and in its ao_complete, call next stage work (memory restore).
> >
> > Now thinking it again, yes, I think one ao could be OK. The two work should
> > be independent, then we can simply do them parallelly, so don't need a separate
> > ao operation for qemu-img work completion. In this way, one ao is enough.
> >
>
> I think what you are saying is right, but I would suggest you take a
> look at "Some libxl operations can take a long time" in libxl.h to make
> sure.
>
> In general any libxl op which can take a long time can be made async by
> adding a single ao to it. That op is then treated as one long op,
> regardless of how many subops it spawns internally.
>
> But if the op you are talking about is actually multiple ops done by the
> application then multiple ao's are needed.
>
> IOW each libxl_* has a single ao. If an app is calling multiple libxl_*
> functions then each needs an ao of its own.
After reading the libxl.h, libxl_domain_suspend and other codes, I think
I could do the long running event one-by-one. Take "revert domain snapshot"
as example:

First, fork process to do disk snapshot revert through qemu-img, when
child process exits enters callback e.g. helper_exited(). In this function,
start second stage work: restore memory (another child process and set callback).
When restore memory process exits, enters its callback, here do remaining work
if there is and return ao_complete. Code like this:

static void helper_exited(libxl__egc *egc, libxl__ev_child *ch,
                          pid_t pid, int status);
static void memory_retore_callback();

libxl_domain_snapshot_restore(libxl_ctx *ctx, uint32_t domid,
                              libxl_domain_snapshot *snapshot,
                              const libxl_asyncop_how *ao_how)
{
    AO_CREATE(ctx, domid, ao_how);

    //revert disk snapshot
    ...
    eid_t pid = libxl__ev_child_fork(gc, child, helper_exited);
    ...


    return AO_INPROGRESS;
}

static void helper_exited(libxl__egc *egc, libxl__ev_child *ch,
                          pid_t pid, int status)
{
    //set memory_retore_callback
    //call memory retore
}

static void memory_retore_callback()
{
    //write domain snapshot configuraiton(libxl-json format)
    ao_complete();
}

How do you think about it?

regards

bamvor
>
> Ian.

15:12 2014-07-16
    /* libxl owns SIGCHLD all the time, but it must only reap its own
     * children.  The application will reap its own children
     * synchronously with waitpid, without the assistance of SIGCHLD. */
    libxl_sigchld_owner_libxl_always_selective_reap,
} libxl_sigchld_owner;

17:52 2014-07-16
hvm_save()(common/hvm/save.c)

21:45 2014-07-16
ps: 我都要走了，我才第一次用了screen shot的delay功能。。。

13:55 2014-07-17
hp convergedsystem 900 for HANA

openSUSE chairman
Vincent Untz -> Richard Brown

14:30 2014-07-17
suse calendar
https://projects.nue.suse.com

13:06 2014-7-17
Q1FY15
suse 47.9m, target 46.2m

Q1FY15
teradata OEM 3.9m
huawei OEM 1.9m

Bookings
NEW, RENEWAL区别？

Q1FY15 ten 10 opportunity.
qualcomm 2.9m

